import numpy as np
import time

# Objective function (Sphere)
def f(x):
    return np.sum(x**2)

# Grey Wolf Optimizer
def GWO(dim=10, search_agents=20, max_iter=100):
    lb, ub = -10, 10
    positions = np.random.uniform(lb, ub, (search_agents, dim))

    # α, β, δ wolves
    Alpha_pos = np.zeros(dim)
    Beta_pos = np.zeros(dim)
    Delta_pos = np.zeros(dim)

    Alpha_score = float("inf")
    Beta_score = float("inf")
    Delta_score = float("inf")

    early_stop = int(max_iter * 0.6)  # incomplete execution (stop at 60%)

    for t in range(max_iter):
        for i in range(search_agents):
            positions[i] = np.clip(positions[i], lb, ub)
            fitness = f(positions[i])

            if fitness < Alpha_score:
                Alpha_score = fitness
                Alpha_pos = positions[i].copy()

            elif fitness < Beta_score:
                Beta_score = fitness
                Beta_pos = positions[i].copy()

            elif fitness < Delta_score:
                Delta_score = fitness
                Delta_pos = positions[i].copy()

        a = 2 - t * (2 / max_iter)

        for i in range(search_agents):
            for j in range(dim):
                r1, r2 = np.random.rand(), np.random.rand()
                A1 = 2 * a * r1 - a
                C1 = 2 * r2
                D_alpha = abs(C1 * Alpha_pos[j] - positions[i][j])
                X1 = Alpha_pos[j] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2 = 2 * a * r1 - a
                C2 = 2 * r2
                D_beta = abs(C2 * Beta_pos[j] - positions[i][j])
                X2 = Beta_pos[j] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3 = 2 * a * r1 - a
                C3 = 2 * r2
                D_delta = abs(C3 * Delta_pos[j] - positions[i][j])
                X3 = Delta_pos[j] - A3 * D_delta

                positions[i][j] = (X1 + X2 + X3) / 3

        # Late execution simulation
        time.sleep(0.15)

        print(f"Iter {t+1} | Alpha Score: {Alpha_score:.6f}")

        # Stop early (incomplete execution)
        if t == early_stop:
            print("\n⚠️ Early stopping triggered (incomplete execution)\n")
            break

    return Alpha_pos, Alpha_score


# Run GWO
best_pos, best_score = GWO(dim=10, search_agents=20, max_iter=100)
print("\nBest Found Position:", best_pos)
print("Best Score:", best_score)
